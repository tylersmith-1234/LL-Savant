{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/tyler/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import configparser\n",
    "import requests\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "from constants_funcs import int_or_float_or_str, EmbeddingType, QuestionCategory\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(u, v):\n",
    "    return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))\n",
    "def generate_embeddings(data: pd.DataFrame, column: str, embeddingType: EmbeddingType):\n",
    "    if (embeddingType == EmbeddingType.Sentence):\n",
    "        sentence_tokens = [word_tokenize(str(sentence).lower()) for sentence in data[column]]\n",
    "        tagged_data = [TaggedDocument(words=st, tags=[str(i)]) for i, st in enumerate(sentence_tokens)]\n",
    "        max_epochs = 100\n",
    "        vec_size = 20\n",
    "        alpha = 0.025\n",
    "\n",
    "        model = Doc2Vec(vector_size=vec_size,\n",
    "                        alpha=alpha, \n",
    "                        min_alpha=0.00025,\n",
    "                        min_count=1,\n",
    "                        dm =1,\n",
    "                        epochs=40)\n",
    "        \n",
    "        model.build_vocab(tagged_data)\n",
    "        model.save(f\"emb_{embeddingType.name}_{column}_d2v.model\")\n",
    "        print(\"Model Saved\")\n",
    "        sentence_vectors = [model.infer_vector(sentence) for sentence in sentence_tokens]\n",
    "        # auto-save new vectors as column in dataframe so user doesnt have to\n",
    "        data[f'{column}_{embeddingType.name}_emb'] = sentence_vectors\n",
    "        return sentence_vectors\n",
    "    elif embeddingType == EmbeddingType.Word:\n",
    "        print('word embedding not implemented yet')\n",
    "    else:\n",
    "        print('pick a valid embedding enum type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n",
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "# example embedding turning question history's question and answer columns into embeddings.\n",
    "fqh = pd.read_csv('./FULL_QUESTION_HISTORY.csv')\n",
    "fqh.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "fqh_q_vecs = generate_embeddings(fqh, 'question', EmbeddingType.Sentence)\n",
    "fqh_a_vecs = generate_embeddings(fqh, 'answer', EmbeddingType.Sentence)\n",
    "fqh.to_csv('./FULL_QUESTION_HISTORY_EMBEDDINGS.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3067ead486e059ec00ffe7555bdb889e6e264a24dc711bf108106cc7baee8d5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
